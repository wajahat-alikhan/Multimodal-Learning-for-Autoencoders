# Multimodal-Learning-for-Autoencoders
Repository of my SIGGRAPH Asia 2024 work (poster).

In Multimodal Autoencoder the image is reconstructed using both image and text as inputs, rather than only image as an input.

Following figure shows the architecture daigram and training scheme of our Multimodal Autoencoder.
![Architecture](Images/z2.png "Architecture")

The qualititaive results on CIFAR-10 are as follows.
![Results](Images/z1.png "Results")

Images reconstructed from both image and text inputs are better than only one modality as an input.
